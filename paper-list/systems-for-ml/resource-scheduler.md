# Resource Scheduler

## Deep Learning Training Schedulers

| Name                          |                          Conf/Journal                          | Institution                                                                                        | Links                                                                                                                                                                                                                                                                                                                                             | Remarks                                                                                                                                       |
| ----------------------------- | :------------------------------------------------------------: | -------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------- |
| **Lyra**                      | [EuroSys 2023](../../reading-notes/conference/eurosys-2023.md) | <ul><li>ByteDance</li><li>CityU</li><li>CUHK</li></ul>                                             | <ul><li><a href="../../reading-notes/miscellaneous/arxiv/2022/aryl-an-elastic-cluster-scheduler-for-deep-learning.md">Personal Notes</a></li><li><a href="https://arxiv.org/abs/2202.07896">arXiv</a></li></ul>                                                                                                                                   | Loan idle inference GPU servers for elastic training jobs.                                                                                    |
| **Lucid**                     |   [ASPLOS 2023](../../reading-notes/conference/asplos-2023/)   | <ul><li>NTU</li><li>Shanghai AI Lab</li><li>SenseTime</li></ul>                                    | <ul><li><a href="../../reading-notes/conference/asplos-2023/lucid-a-non-intrusive-scalable-and-interpretable-scheduler-for-deep-learning-training-jobs.md">Personal Notes</a></li><li><a href="https://dl.acm.org/doi/10.1145/3575693.3575705">Paper</a></li><li><a href="https://github.com/S-Lab-System-Group/Lucid">Code</a></li></ul>         | Interpretability.                                                                                                                             |
| **Shockwave**                 |     [NSDI 2023](../../reading-notes/conference/nsdi-2023/)     | <ul><li>UW-Madison</li><li>UT-Austin</li></ul>                                                     | <ul><li><a href="../../reading-notes/conference/nsdi-2023/shockwave-fair-and-efficient-cluster-scheduling-for-dynamic-adaptation-in-machine-learning.md">Personal Notes</a></li><li><a href="https://www.usenix.org/conference/nsdi23/presentation/zheng">Paper</a></li><li><a href="https://github.com/uw-mad-dash/shockwave">Code</a></li></ul> | Elastic resource requirements; extend market theory.                                                                                          |
| **Muri**                      |                          SIGCOMM 2022                          | <ul><li>PKU</li><li>ByteDance</li></ul>                                                            | <ul><li><a href="../../reading-notes/conference/sigcomm-2022/multi-resource-interleaving-for-deep-learning-training.md">Personal Notes</a></li><li><a href="https://dl.acm.org/doi/10.1145/3544216.3544224">Paper</a></li><li><a href="https://github.com/Rivendile/Muri">Code</a></li></ul>                                                      | Pack jobs along multiple resource types in the time dimension; integrate with PyTorch.                                                        |
| **Singularity**               |                        arXiv 2202.07848                        | <ul><li>Microsoft</li></ul>                                                                        | <ul><li><a href="../../reading-notes/miscellaneous/arxiv/singularity-planet-scale-preemptive-and-elastic-scheduling-of-ai-workloads.md">Personal Notes</a></li><li><a href="https://arxiv.org/abs/2202.07848">Paper</a></li></ul>                                                                                                                 | Live GPU job migration.                                                                                                                       |
| **Pollux**                    |            [OSDI 2021](../../Conference/OSDI-2021/)            | <ul><li>Petuum</li><li>CMU</li></ul>                                                               | <ul><li><a href="../../Conference/OSDI-2021/pollux.md">Personal Notes</a></li><li><a href="https://www.usenix.org/conference/osdi21/presentation/qiao">Paper</a></li><li><a href="https://github.com/petuum/adaptdl">Code</a></li></ul>                                                                                                           | Co-adaptively _allocates resources_ (number of GPUs) and _tunes the hyperparameters_ (batch size and learning rate) for all DL training jobs. |
| **MAPA**                      |                             SC 2021                            | <ul><li>UC Riverside</li><li>Pacific Northwest National Lab</li><li>University of Sydney</li></ul> | <ul><li><a href="https://dl.acm.org/doi/10.1145/3458817.3480853">Paper</a></li><li><a href="https://github.com/socal-ucr/MAPA">Code</a></li></ul>                                                                                                                                                                                                 | Consider multi-GPU accelerator topologies such as _single/double NVLink_.                                                                     |
| **Astraea**                   |                            TPDS 2021                           | <ul><li>PKU</li><li>NTU</li><li>SenseTime</li></ul>                                                | <ul><li><a href="https://ieeexplore.ieee.org/abstract/document/9655467">Paper</a></li></ul>                                                                                                                                                                                                                                                       | Long-term GPU-time fairness.                                                                                                                  |
| **AntMan**                    |            [OSDI 2020](../../Conference/OSDI-2020/)            | <ul><li>Alibaba</li></ul>                                                                          | <ul><li><a href="https://www.usenix.org/conference/osdi20/presentation/xiao">Paper</a></li><li><a href="https://github.com/alibaba/GPU-scheduler-for-deep-learning">Code</a></li></ul>                                                                                                                                                            | Co-locate resource-guarantee and best-effort jobs.                                                                                            |
| **HiveD**                     |            [OSDI 2020](../../Conference/OSDI-2020/)            | <ul><li>MSRA</li></ul>                                                                             | <ul><li><a href="../../Conference/OSDI-2020/hived.md">Personal Notes</a></li><li><a href="https://www.usenix.org/conference/osdi20/presentation/zhao-hanyu">Paper</a></li><li><a href="https://github.com/microsoft/hivedscheduler">Code</a></li></ul>                                                                                            | Virtual private clusters; resource isolation and management for multi-tenant clusters.                                                        |
| **Gavel**                     |            [OSDI 2020](../../Conference/OSDI-2020/)            | <ul><li>MSR</li><li>Stanford</li></ul>                                                             | <ul><li><a href="https://www.usenix.org/conference/osdi20/presentation/narayanan-deepak">Paper</a></li><li><a href="https://github.com/stanford-futuredata/gavel">Code</a></li></ul>                                                                                                                                                              | Consider _performance heterogeneity_ across multiple accelerator types.                                                                       |
| **Themis**                    |                          EuroSys 2020                          | <ul><li>UW-Madison</li><li>MSR</li></ul>                                                           | <ul><li><a href="https://www.usenix.org/conference/nsdi20/presentation/mahajan">Paper</a></li></ul>                                                                                                                                                                                                                                               | Long-term fairness.                                                                                                                           |
| **GandivaFair**               |                          EuroSys 2019                          | <ul><li>MSR India</li></ul>                                                                        | <ul><li><a href="https://dl.acm.org/doi/10.1145/3342195.3387555">Paper</a></li></ul>                                                                                                                                                                                                                                                              | Achieve efficiency and fairness despite cluster heterogeneity.                                                                                |
| **Tiresias**                  |                            NSDI 2019                           | <ul><li><a href="https://symbioticlab.org/">UMich SymbioticLab</a></li></ul>                       | <ul><li><a href="https://www.usenix.org/conference/nsdi19/presentation/gu">Paper</a></li><li><a href="https://github.com/SymbioticLab/Tiresias">Code</a></li></ul>                                                                                                                                                                                | Relax consolidated placement constraint.                                                                                                      |
| **Gandiva**                   |                            OSDI 2018                           | <ul><li>MSRA</li></ul>                                                                             | <ul><li><a href="https://www.usenix.org/conference/osdi18/presentation/xiao">Paper</a></li></ul>                                                                                                                                                                                                                                                  | Hyper-parameter tuning jobs; job packing; migration; grow-shrink; time-slicing.                                                               |
| **Optimus**                   |                          EuroSys 2018                          | <ul><li>HKU</li><li>ByteDance</li></ul>                                                            | <ul><li><a href="https://dl.acm.org/doi/10.1145/3190508.3190517">Paper</a></li><li><a href="https://github.com/pengyanghua/optimus">Code</a></li></ul>                                                                                                                                                                                            | Minimize JCT based on _online resource-performance models_.                                                                                   |
| **Topology-aware scheduling** |                             SC 2017                            | <ul><li>Barcelona Supercomputing Center</li><li>IBM Watson Research Center</li></ul>               | <ul><li><a href="https://dl.acm.org/doi/10.1145/3126908.3126933">Paper</a></li><li><a href="https://github.com/HiEST/gpu-topo-aware">Code</a></li></ul>                                                                                                                                                                                           | Consider multiple link technologies such as _PCI-e_ and _NVLink_.                                                                             |

## ML Training Schedulers

|   Name   | Conference                                             | Institution                 | Links                                                                                                                                                                                                                                 |                                                                                                      |
| :------: | ------------------------------------------------------ | --------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------- |
| **SLAQ** | [SoCC 2017](../../reading-notes/conference/socc-2017/) | <ul><li>Princeton</li></ul> | <ul><li><a href="../../reading-notes/conference/socc-2017/slaq-quality-driven-scheduling-for-distributed-machine-learning.md">Personal Notes</a></li><li><a href="https://dl.acm.org/doi/10.1145/3127479.3127490">Paper</a></li></ul> | Fine-grained job-level scheduler; leverage the _iterative nature_ of general ML training algorithms. |

## Trace Analysis

|        Source        | Conference | Institution                             | Links                                                                                                                                                                                                   | Remarks                |
| :------------------: | ---------- | --------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------- |
|    **Alibaba PAI**   | NSDI 2022  | <ul><li>HKUST</li><li>Alibaba</li></ul> | <ul><li><a href="https://www.usenix.org/conference/nsdi22/presentation/weng">Paper</a></li><li><a href="https://github.com/alibaba/clusterdata/tree/master/cluster-trace-gpu-v2020">Trace</a></li></ul> | GPU sharing traces.    |
| **SenseTime Helios** | SC 2021    | <ul><li>NTU</li><li>SenseTime</li></ul> | <ul><li><a href="https://dl.acm.org/doi/10.1145/3458817.3476223">Paper</a></li><li><a href="https://github.com/S-Lab-System-Group/HeliosData">Trace</a></li></ul>                                       | DL training workloads. |
| **Microsoft Philly** | ATC 2019   | <ul><li>MSR</li></ul>                   | <ul><li><a href="https://www.usenix.org/conference/atc19/presentation/jeon">Paper</a></li><li><a href="https://github.com/msr-fiddle/philly-traces">Trace</a></li></ul>                                 | DL training workloads. |
|    **Alibaba PAI**   | IISWC 2019 | <ul><li>Alibaba</li></ul>               | <ul><li><a href="https://ieeexplore.ieee.org/document/9042047">Paper</a></li></ul>                                                                                                                      | DL training workloads. |

## Survey

| Title                                                                                 | Conf             | Institute                                           | Links                                                                                                                                                                      |
| ------------------------------------------------------------------------------------- | ---------------- | --------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Deep learning workload scheduling in GPU datacenters: Taxonomy, challenges and vision | arXiv 2205.11913 | <ul><li>NTU</li><li>PKU</li><li>SenseTime</li></ul> | <ul><li><a href="https://arxiv.org/abs/2205.11913">arXiv</a></li><li><a href="https://github.com/S-Lab-System-Group/Awesome-DL-Scheduling-Papers">Paper List</a></li></ul> |
