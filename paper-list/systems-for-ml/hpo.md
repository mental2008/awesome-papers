# Hyper-Parameter Tuning (HPO)

HPO: Hyper-Parameter Optimization

## Optimizing HPO Workloads

|      Name      | Conference                                                   | Institution                                   | Links                                                                                                                                                                 | Remarks                                                 |
| :------------: | ------------------------------------------------------------ | --------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------- |
|    **Hydro**   | [OSDI 2023](../../reading-notes/conference/osdi-2023.md)     | <ul><li>NTU</li><li>Shanghai AI Lab</li></ul> | <ul><li><a href="https://www.usenix.org/conference/osdi23/presentation/hu">Paper</a></li><li><a href="https://github.com/S-Lab-System-Group/Hydro">Code</a></li></ul> | Surrogate models; co-locate HPO jobs with LLM training. |
|    **SEER**    | [SoCC 2021](../../reading-notes/conference/socc-2021.md)     | <ul><li>UC Berkeley</li></ul>                 | <ul><li><a href="https://dl.acm.org/doi/10.1145/3472883.3486989">Paper</a></li></ul>                                                                                  |                                                         |
| **RubberBand** | [EuroSys 2021](../../reading-notes/conference/eurosys-2021/) | <ul><li>UC Berkeley</li></ul>                 | <ul><li><a href="https://dl.acm.org/doi/10.1145/3447786.3456245">Paper</a></li></ul>                                                                                  |                                                         |

## HPO for System

|      Name     | Conference                                               | Institution                             | Links                                                                                                                                                  | Remarks                                                       |
| :-----------: | -------------------------------------------------------- | --------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------- |
| **Morphling** | [SoCC 2021](../../reading-notes/conference/socc-2021.md) | <ul><li>HKUST</li><li>Alibaba</li></ul> | <ul><li><a href="https://dl.acm.org/doi/10.1145/3472883.3486987">Paper</a></li><li><a href="https://github.com/kubedl-io/morphling">Code</a></li></ul> | Meta-learning for tuning parameters in model serving systems. |
