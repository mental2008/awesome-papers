# Model Serving

## Inference Serving System

|          Name          | Conference                               | Institution                   | Links                                                                                                                                                                                                                                                             | Remarks                                      |
| :--------------------: | ---------------------------------------- | ----------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------- |
|       **INFaaS**       | [ATC 2021](../../Conference/ATC-2021/)   | <ul><li>Stanford</li></ul>    | <ul><li><a href="https://www.usenix.org/conference/atc21/presentation/romero">Paper</a></li><li><a href="https://github.com/stanford-mast/INFaaS">Code</a></li></ul>                                                                                              | Consider model-variants.                     |
|       **Clipper**      | [NSDI 2017](../../Conference/NSDI-2017/) | <ul><li>UC Berkeley</li></ul> | <ul><li><a href="../../Conference/NSDI-2017/clipper.md">Personal Notes</a></li><li><a href="https://www.usenix.org/conference/nsdi17/technical-sessions/presentation/crankshaw">Paper</a></li><li><a href="https://github.com/ucbrise/clipper">Code</a></li></ul> | Caching, batching, adaptive model selection. |
| **TensorFlow Serving** | NIPS 2017 Workshop on ML Systems         | <ul><li>Google</li></ul>      | <ul><li><a href="https://arxiv.org/abs/1712.06139">Paper</a></li></ul>                                                                                                                                                                                            |                                              |

## Auto-Configuration System

|      Name     | Conference                                             | Institution                                                          | Links                                                                                                                                                                                                                                                                                                                                  | Remarks                                       |
| :-----------: | ------------------------------------------------------ | -------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------- |
|   **Falcon**  | [SoCC 2022](../../reading-notes/conference/socc-2022/) | <ul><li>Institute of Software, Chinese Academy of Sciences</li></ul> | <ul><li><a href="../../reading-notes/conference/socc-2022/serving-unseen-deep-learning-model-with-near-optimal-configurations-a-fast-adaptive-search-approach.md">Personal Notes</a></li><li><a href="https://dl.acm.org/doi/10.1145/3542929.3563485">Paper</a></li><li><a href="https://github.com/dos-lab/Falcon">Code</a></li></ul> | Characterize a DL model by its key operators. |
| **Morphling** | SoCC 2021                                              | <ul><li>HKUST</li><li>Alibaba</li></ul>                              | <ul><li><a href="https://dl.acm.org/doi/10.1145/3472883.3486987">Paper</a></li><li><a href="https://github.com/kubedl-io/morphling">Code</a></li></ul>                                                                                                                                                                                 | Meta learning; bayesian optimization.         |

## Survey

| Survey                                                                                          |                     Conference                    | Institute                                                                                                                   | Links                                                                  |
| ----------------------------------------------------------------------------------------------- | :-----------------------------------------------: | --------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------- |
| A survey of multi-tenant deep learning inference on GPU                                         | MLSys 2022 Workshop on Cloud Intelligence / AIOps | <ul><li>George Mason University</li><li>Microsoft</li><li>University of Maryland</li></ul>                                  | <ul><li><a href="https://arxiv.org/abs/2203.09040">arXiv</a></li></ul> |
| A survey of large-scale deep learning serving system optimization: Challenges and opportunities |                  arXiv 2111.14247                 | <ul><li>George Mason University</li><li>Microsoft</li><li>University of Pittsburgh</li><li>University of Maryland</li></ul> | <ul><li><a href="https://arxiv.org/abs/2111.14247">arXiv</a></li></ul> |
